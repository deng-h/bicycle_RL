## 24/10/30
- 完成checkpoints Wrapper和getCameraImage方法优化
- 没有训练成果的一天
## 24/10/31
- 优化了getCameraImage方法
- 把特征提取和智能体的训练分离，这样可以加快智能体的训练，[文章](https://arxiv.org/pdf/1901.08651#page=1.29)
- 提供过往的actions和states,解决通信延时的方法之一是提供过往的actions和states，把这些一起作为输入
## 24/11/02
- 引入RL Zoo框架，修改自行车模型代码(主要是设置服务器的ID)
- 理解了RL Zoo框架的基本结构
## 24/11/03
- 把特征提取和智能体的训练分离，这样可以加快智能体的训练，
[这篇文章](https://arxiv.org/pdf/1901.08651#page=1.29)
主要用的是state representation learning(SRL)方法，
但是我看网上说这种方法对于on-policy方法不适用
## 24/11/04
- 理解框架的plot部分，感觉和他的项目深度耦合，不如自己写plot方法
## 24/11/05
- 增加PPO网络的层数和神经元数，2层->3层，256个神经元->512个神经元